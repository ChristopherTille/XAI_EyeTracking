{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902c9d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import skdim\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import keras\n",
    "import cv2\n",
    "import skdim\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from skopt import gp_minimize\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from itertools import combinations\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import Lasso, lars_path, Ridge, ElasticNet, LogisticRegression, SGDClassifier\n",
    "from collections import Counter\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742a5b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data and convert to data and label\n",
    "def import_data(folder_path, train):\n",
    "  \"\"\"\n",
    "  input:\n",
    "    dataset is whether you want to get the training or test data\n",
    "    folder_path is the link to the file containing the image data (e.g.\"XXX\")\n",
    "    target_size is the desired size after resizing the images (e.g. 224*224 pixels)\n",
    "  output:\n",
    "    images_array is the array containing the pixel values of the images with shape (8, 224, 224, 3) and value range in [0,255]\n",
    "    str_label_array is the array containing the string labels of the images\n",
    "    int_label_array is the array containing the integer labels of the images\n",
    "  \"\"\"\n",
    "\n",
    "  if train==1:\n",
    "    folder_path = os.path.join(folder_path, \"Train 2800\")\n",
    "    print('Importing Training data...')\n",
    "  elif train == 2:\n",
    "    print('Importing Explanation data...')\n",
    "    folder_path = os.path.join(folder_path, \"Pool25\")\n",
    "  elif train == 0:\n",
    "    print('Importing Test data...')\n",
    "    folder_path = os.path.join(folder_path, \"Test 700\")  \n",
    "\n",
    "  class_folders = [f for f in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, f))]\n",
    "\n",
    "  # Initialize an empty list to store pixel values\n",
    "  images = []\n",
    "  ground_truth_labels = []\n",
    "\n",
    "  for class_folder in class_folders:\n",
    "        class_folder_path = os.path.join(folder_path, class_folder)\n",
    "        image_files = [f for f in os.listdir(class_folder_path) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "\n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(class_folder_path, image_file)\n",
    "            img = cv2.imread(image_path)\n",
    "            #resized_img = cv2.resize(img, target_size)\n",
    "            images.append(img)\n",
    "            ground_truth_labels.append(class_folder)\n",
    "\n",
    "  images_array = np.array(images)\n",
    "  print('Imported', images_array.shape[0], 'images of shape', images_array.shape[1:4])\n",
    "\n",
    "\n",
    "  str_ground_truth_labels = np.array(ground_truth_labels)\n",
    "\n",
    "  label_mapping = {\"Tel-Aviv\": \"TelAviv\",\n",
    "          \"West Jerusalem\": \"Jerusalem\",\n",
    "          \"WestJerusalem\": \"Jerusalem\",\n",
    "          \"Hamburg\": \"Hamburg\",\n",
    "          \"Berlin\": \"Berlin\"}\n",
    "\n",
    "  # Map original class labels to new label names\n",
    "  str_ground_truth_labels = np.array([label_mapping[label] for label in str_ground_truth_labels])\n",
    "  print('Remapped to the following classes: ', np.unique(str_ground_truth_labels, return_counts=True)[0])\n",
    "  print('Found', np.unique(str_ground_truth_labels, return_counts=True)[1], 'examples for the different classes respectively')\n",
    "\n",
    "  # Assuming you have a function strLabel_to_intLabel_mapping that converts string labels to integers\n",
    "  int_ground_truth_labels = strLabel_to_intLabel_mapping(str_ground_truth_labels)\n",
    "\n",
    "  cat_ground_truth_labels = to_categorical(int_ground_truth_labels, 4)\n",
    "\n",
    "  return images_array, int_ground_truth_labels, cat_ground_truth_labels, str_ground_truth_labels\n",
    "\n",
    "# Map string labels (e.g. \"Jerusalem\") to integer labels (e.g. 1)\n",
    "def strLabel_to_intLabel_mapping(y):\n",
    "  \"\"\"\n",
    "  input:\n",
    "    y is the array of string labels\n",
    "  output:\n",
    "    int_labels_mapped is the array of the corresponding integer labels\n",
    "  \"\"\"\n",
    "  # Create a dictionary to map string labels to int labels\n",
    "  label_mapping = {'TelAviv': 2, 'Jerusalem': 3, 'Berlin': 0, 'Hamburg': 1}\n",
    "  # Map string labels to int labels using the created dictionary\n",
    "  int_labels_mapped = np.array([label_mapping[val] for val in y])\n",
    "  return int_labels_mapped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7f7545",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_int_train, y_cat_train, y_str_train = import_data(\"XXX\", train = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7ce6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_int_test, y_cat_test, y_str_test = import_data(\"XXX\", train = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6a27cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_expl, y_int_expl, y_cat_expl, y_str_expl = import_data(\"XXX\", train = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ad25ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    i = random.randint(0,99)\n",
    "    plt.imshow(cv2.cvtColor(X_expl[i], cv2.COLOR_BGR2RGB))\n",
    "    plt.title([y_str_expl[i], y_int_expl[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99c22da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1, X_val, y_train_1, y_val = train_test_split(X_train, y_cat_train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8509873",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.RandomRotation(0.2),\n",
    "])\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "IMG_SIZE = (448, 448)\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b202a93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da6874d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cf92c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e158efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(4, activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da95efed",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd4be9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(448, 448, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e86e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996839f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f49af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred0 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12d7840",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate on training data\n",
    "accuracy = accuracy_score(y_int_test, np.argmax(pred0, axis =1))\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Generate a classification report\n",
    "class_report = classification_report(y_int_test, np.argmax(pred0, axis =1))\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Generate a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_int_test, np.argmax(pred0, axis =1))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cd7f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epochs = 10\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath = 'XXX.keras', verbose = 2, save_best_only = True)\n",
    "\n",
    "history = model.fit(x = X_train_1, y = y_train_1,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=(X_val,y_val), callbacks = [checkpointer], verbose = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f291d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de68ce35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "#plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylim([min(plt.ylim()),0.7])\n",
    "plt.title('Training and Validation Accuracy (first training cycle)')\n",
    "plt.savefig('acc_first_training_cycle.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d83eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.subplot(2, 1, 2)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0.6,1.5])\n",
    "plt.title('Training and Validation Loss (first training cycle)')\n",
    "plt.xlabel('epoch')\n",
    "plt.savefig('loss_first_training_cycle.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c95443",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred0 = np.argmax(model.predict(X_test), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f051c67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate on training data\n",
    "accuracy = accuracy_score(y_int_test, pred0)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Generate a classification report\n",
    "class_report = classification_report(y_int_test, pred0)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Generate a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_int_test, pred0)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3540409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.RandomRotation(0.2),\n",
    "])\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "IMG_SIZE = (448, 448)\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 75\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable = False\n",
    "\n",
    "inputs = tf.keras.Input(shape=(448, 448, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.load_weights('XXX.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75539df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f8fcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate/10),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1223cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f808b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_epochs = 30\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "checkpointer = ModelCheckpoint(filepath = 'XXX.keras', verbose = 2, save_best_only = True)\n",
    "\n",
    "history_fine = model.fit(x = X_train_1, y = y_train_1,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=history.epoch[-1],\n",
    "                         validation_data=(X_val,y_val), callbacks = [checkpointer], verbose = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5190d680",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc += history_fine.history['accuracy']\n",
    "val_acc += history_fine.history['val_accuracy']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce681a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "#plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylim([0.3, 1])\n",
    "plt.plot([initial_epochs,initial_epochs],\n",
    "          plt.ylim(), label='Start Second Cycle of Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy (both training cycles)')\n",
    "plt.savefig('acc_both_training_cycle.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b7932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.subplot(2, 1, 2)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.ylim([0, 1.4])\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.xlabel('epoch')\n",
    "plt.plot([initial_epochs,initial_epochs],\n",
    "         plt.ylim(), label='Start Second Cycle of Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss (both training cycles)')\n",
    "plt.xlabel('epoch')\n",
    "plt.savefig('loss_both_training_cycle.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70cc2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred0 = np.argmax(model.predict(X_test), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991022a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('fine_train_on_array.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df952f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate on training data\n",
    "accuracy = accuracy_score(y_int_test, pred0)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Generate a classification report\n",
    "class_report = classification_report(y_int_test, pred0)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Generate a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_int_test, pred0)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244c64b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred0 = np.argmax(model.predict(X_expl), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2a825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate on training data\n",
    "accuracy = accuracy_score(y_int_expl, pred0)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Generate a classification report\n",
    "class_report = classification_report(y_int_expl, pred0)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Generate a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_int_expl, pred0)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b4c437",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.saving.save_model(model, 'MobileV2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02085915",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
